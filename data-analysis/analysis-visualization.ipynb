{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sAPxf78-W0pm"
      },
      "outputs": [],
      "source": [
        "knitr::opts_chunk$set(echo = TRUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knnn3CkLXEsD"
      },
      "source": [
        "# Install the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i2LB9XmXHV4",
        "outputId": "89d3e69e-34b8-48b4-d765-f97788644228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: ggplot2\n",
            "\n",
            "Loading required package: e1071\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘e1071’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘proxy’\n",
            "\n",
            "\n",
            "Loading required package: tidyverse\n",
            "\n",
            "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
            "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
            "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
            "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
            "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
            "Loading required package: effsize\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘effsize’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "options(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n",
        "\n",
        "if (!require(\"ggplot2\")) install.packages(\"ggplot2\")\n",
        "if (!require(\"e1071\")) install.packages(\"e1071\")\n",
        "if (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n",
        "if (!require(\"dplyr\")) install.packages(\"dplyr\")\n",
        "if (!require(\"effsize\")) install.packages(\"effsize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq5VdEqoehec",
        "outputId": "eca6a408-a8b1-403a-86ba-f20c176805d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘cowplot’, ‘Deriv’, ‘microbenchmark’, ‘numDeriv’, ‘doBy’, ‘SparseM’, ‘MatrixModels’, ‘minqa’, ‘nloptr’, ‘RcppEigen’, ‘carData’, ‘abind’, ‘Formula’, ‘pbkrtest’, ‘quantreg’, ‘lme4’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Warning message:\n",
            "“package ‘grid’ is a base package, and should not be updated”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"car\")\n",
        "install.packages('cowplot')\n",
        "install.packages('grid')\n",
        "install.packages(\"png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpPvH-5oXIzW",
        "outputId": "77fdbe69-61e7-4992-e058-d766a7d18528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: carData\n",
            "\n",
            "\n",
            "Attaching package: ‘car’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:dplyr’:\n",
            "\n",
            "    recode\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:purrr’:\n",
            "\n",
            "    some\n",
            "\n",
            "\n",
            "\n",
            "Attaching package: ‘cowplot’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:lubridate’:\n",
            "\n",
            "    stamp\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "library(\"car\")\n",
        "library('cowplot')\n",
        "library('grid')\n",
        "library(\"png\")\n",
        "\n",
        "library(e1071)\n",
        "library(effsize)\n",
        "\n",
        "library(ggplot2)\n",
        "library(tidyverse)\n",
        "library(dplyr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define some global variables"
      ],
      "metadata": {
        "id": "WCTguW3wwini"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ON_DEVICE <- \"on_device\"\n",
        "REMOTE <- \"remote\"\n",
        "LENGTHS <- c(100, 500, 1000)\n",
        "LENGTH_LABELS <- c(\"short\", \"medium\", \"long\")\n",
        "LENGTH_MAP <- setNames(LENGTHS, LENGTH_LABELS)  # Map lengths to labels\n",
        "# Color mapping for On-Device and Remote using R's native colors\n",
        "COLOR_MAP <- c(on_device = \"coral\",\n",
        "               remote = \"lightblue\")\n",
        "\n",
        "ENERGY <- \"energy_usage_J\"\n",
        "TIME <- \"execution_time\"\n",
        "CPU <- \"cpu_usage\"\n",
        "GPU <- \"gpu_usage\"\n",
        "MEMORY <- \"memory_usage\"\n",
        "\n",
        "METRICS <- c(ENERGY, TIME, CPU, GPU, MEMORY)\n",
        "\n",
        "AXIS_LABELS <- list(\n",
        "  energy_usage_J = \"Energy Usage (J)\",\n",
        "  execution_time = \"Execution Time (%)\",\n",
        "  cpu_usage = \"CPU Usage (%)\",\n",
        "  gpu_usage = \"GPU Usage (%)\",\n",
        "  memory_usage = \"Memory Usage (%)\"\n",
        ")\n",
        "\n",
        "\n",
        "DENSITY_FOLDER <- \"density_plots\"\n",
        "VIOLIN_FOLDER <- \"violin_plots\"\n",
        "QQ_FOLDER <- \"qq_plots\"\n",
        "SCATTER_FOLDER <- \"scatter_plots\"\n",
        "\n",
        "PLOT_FOLDERS <- c(DENSITY_FOLDER, VIOLIN_FOLDER, QQ_FOLDER, SCATTER_FOLDER)\n",
        "\n",
        "WIDTH = 8\n",
        "HEIGHT = 12\n",
        "FONT_MULTIPLIER = 3\n",
        "\n",
        "LLM_NAMES <- c(\n",
        "  \"Qwen 2 1.5B\" = \"qwen2:1.5b\",\n",
        "  \"Gemma 1.1 2B\" = \"gemma:2b\",\n",
        "  \"Phi 3 3B\" = \"phi3:3.8b\",\n",
        "  \"Qwen 2 7B\" = \"qwen2:7b\",\n",
        "  \"Gemma 1.1 7B\" = \"gemma:7b\",\n",
        "  \"Mistral 0.3 7B\" = \"mistral:7b\",\n",
        "  \"Llama 3.1 8B\" = \"llama3.1:8b\"\n",
        ")\n",
        "\n",
        "LLM_SHORT_LABELS <- c(\n",
        "  \"Qwen 2 1.5B\" = \"Q1.5\",\n",
        "  \"Gemma 1.1 2B\" = \"G2\",\n",
        "  \"Phi 3 3B\" = \"P3\",\n",
        "  \"Qwen 2 7B\" = \"Q7\",\n",
        "  \"Gemma 1.1 7B\" = \"G7\",\n",
        "  \"Mistral 0.3 7B\" = \"M7\",\n",
        "  \"Llama 3.1 8B\" = \"L8\"\n",
        ")\n",
        "\n",
        "LLM_COLOR_MAP <- c(\n",
        "  \"#ff0000\",  # Red\n",
        "  \"#ff8000\",  # Orange\n",
        "  \"#ffff00\",  # Yellow\n",
        "  \"#00ff00\",  # Green\n",
        "  \"#00ffff\",  # Cyan (Light Blue)\n",
        "  \"#0000ff\",  # Blue\n",
        "  \"#8000ff\"   # Violet\n",
        ")\n"
      ],
      "metadata": {
        "id": "bd0OxjZewiMS"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJarIovxXLJJ"
      },
      "source": [
        "# Read the run table file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-s7PrsZe9r5",
        "outputId": "25ea145f-bcee-41c3-b2e2-6e8c0c0b7474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             X__run_id X__done       model    method length               topic\n",
            "1  run_32_repetition_9    DONE    qwen2:7b on_device   1000         World War I\n",
            "2 run_34_repetition_27    DONE    qwen2:7b    remote    500       Elvis Presley\n",
            "3 run_10_repetition_17    DONE    gemma:2b    remote    500     John F. Kennedy\n",
            "4 run_21_repetition_14    DONE   phi3:3.8b    remote    100           Tom Brady\n",
            "5  run_4_repetition_11    DONE llama3.1:8b    remote    500        Adolf Hitler\n",
            "6 run_41_repetition_10    DONE  mistral:7b    remote   1000 William Shakespeare\n",
            "  execution_time cpu_usage gpu_usage memory_usage codecarbon__energy_consumed\n",
            "1      49.812157     3.151    95.507       73.341                0.0001414828\n",
            "2      15.413524     2.888     0.196       51.100                0.0000152000\n",
            "3       9.873243     5.033     0.448       55.267                0.0000058000\n",
            "4       9.877062    10.767     0.459       52.367                0.0000058000\n",
            "5      15.385836     4.588     0.225       53.200                0.0000151000\n",
            "6      14.300526     6.814     0.091       52.629                0.0000132000\n",
            "  energy_usage_J\n",
            "1       509.3382\n",
            "2        54.6000\n",
            "3        20.9000\n",
            "4        20.9000\n",
            "5        54.3000\n",
            "6        47.6000\n"
          ]
        }
      ],
      "source": [
        "dataset <- read.csv(\"./run_table.csv\")\n",
        "print(head(dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27XNfSx-A-nO"
      },
      "source": [
        "# H1 Analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a Function to Remove Outliers using IQR method (works on multiple columns of a dataset)"
      ],
      "metadata": {
        "id": "L2R05BKszUYX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yQ8KvbrPA-GM"
      },
      "outputs": [],
      "source": [
        "# Function to remove outliers using the IQR method\n",
        "remove_outliers <- function(data, columns) {\n",
        "  # Initialize filtered data as the original data\n",
        "  filtered_data <- data\n",
        "\n",
        "  # Loop over each column and apply IQR outlier filtering\n",
        "  for (column in columns) {\n",
        "    Q1 <- quantile(filtered_data[[column]], 0.25, na.rm = TRUE)\n",
        "    Q3 <- quantile(filtered_data[[column]], 0.75, na.rm = TRUE)\n",
        "    IQR_value <- Q3 - Q1\n",
        "    lower_bound <- Q1 - 1.5 * IQR_value\n",
        "    upper_bound <- Q3 + 1.5 * IQR_value\n",
        "\n",
        "    # Filter rows where the column values are within bounds\n",
        "    filtered_data <- filtered_data %>%\n",
        "      filter(filtered_data[[column]] >= lower_bound & filtered_data[[column]] <= upper_bound)\n",
        "  }\n",
        "\n",
        "  return(filtered_data)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter dataset into 3 blocks & 2 treatments while removing outliers based on `ENERGY` column\n",
        "- 2 Treatments:\n",
        "  - `on_device`\n",
        "  - `remote`\n",
        "\n",
        "- 3 Blocks (blocking factor: requested LLM content length):\n",
        "  - Short (100 words)\n",
        "  - Medium (500 words)\n",
        "  - Long (1000 words)\n",
        "\n",
        "--> 6 subsets"
      ],
      "metadata": {
        "id": "lrdR5TFwzmBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store subsets in a named list for easy access\n",
        "subset_data <- list()\n",
        "\n",
        "# Loop over method and length combinations, using labels\n",
        "for (method in c(ON_DEVICE, REMOTE)) {\n",
        "  for (label in names(LENGTH_MAP)) {\n",
        "    length_value <- LENGTH_MAP[[label]]\n",
        "    subset_name <- paste(method, label, sep = \"_\")  # e.g., \"on_device_short\"\n",
        "\n",
        "    # Filter the dataset\n",
        "    filtered_data <- dataset %>%\n",
        "      filter(method == !!method, length == length_value)\n",
        "\n",
        "    # Call the remove_outliers function with the filtered data and the metrics columns\n",
        "    subset_data[[subset_name]] <- remove_outliers(filtered_data, METRICS)\n",
        "  }\n",
        "}\n",
        "\n",
        "# Access example: on-device data for \"short\" length\n",
        "# on_device_data_short <- subset_data[[\"on_device_short\"]]"
      ],
      "metadata": {
        "id": "xsCVgHCSy5Tp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table: Mean, Median, and Standard Deviation (SD) of Energy Usage and Performance Metrics for Fetching LLM Content On-Device vs. Remote Across Varying Content Lengths"
      ],
      "metadata": {
        "id": "KpaBYFwm06li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare LaTeX table header\n",
        "cat(\"\\\\begin{table*}[htbp]\\n\")\n",
        "cat(\"    \\\\centering\\n\")\n",
        "cat(\"    \\\\caption{Mean, Median, and Standard Deviation (SD) of Energy Usage and Performance Metrics for Fetching LLM Content On-Device vs. Remote Across Varying Content Lengths}\\n\")\n",
        "cat(\"    \\\\scalebox{0.8}{\\n\")\n",
        "cat(\"    \\\\begin{tabular}{|l|l|ccc|ccc|ccc|ccc|ccc|}\\n\")\n",
        "cat(\"        \\\\hline\\n\")\n",
        "cat(\"        \\\\multirow{2}{*}{\\\\textbf{Content Length}} & \\\\multirow{2}{*}{\\\\textbf{Treatment}} & \\\\multicolumn{3}{c|}{\\\\textbf{Energy Usage (Joule)}} & \\\\multicolumn{3}{c|}{\\\\textbf{Execution Time (second)}} & \\\\multicolumn{3}{c|}{\\\\textbf{Average CPU Usage (\\\\%)}} & \\\\multicolumn{3}{c|}{\\\\textbf{Average GPU Usage (\\\\%)}} & \\\\multicolumn{3}{c|}{\\\\textbf{Average Memory Usage (\\\\%)}} \\\\\\\\ \\n\")\n",
        "cat(\"        \\\\cline{3-17}\\n\")\n",
        "cat(\"        & & \\\\textbf{Mean} & \\\\textbf{Median} & \\\\textbf{SD} & \\\\textbf{Mean} & \\\\textbf{Median} & \\\\textbf{SD} & \\\\textbf{Mean} & \\\\textbf{Median} & \\\\textbf{SD} & \\\\textbf{Mean} & \\\\textbf{Median} & \\\\textbf{SD} & \\\\textbf{Mean} & \\\\textbf{Median} & \\\\textbf{SD} \\\\\\\\ \\n\")\n",
        "cat(\"        \\\\hline\\n\")\n",
        "\n",
        "# Loop over lengths first and then methods to populate rows\n",
        "for (label in names(LENGTH_MAP)) {\n",
        "  length_value <- LENGTH_MAP[[label]]\n",
        "  for (method in c(ON_DEVICE, REMOTE)) {\n",
        "    subset_name <- paste(method, label, sep = \"_\")\n",
        "\n",
        "    # Extract the subset data\n",
        "    data <- subset_data[[subset_name]]\n",
        "\n",
        "    # Calculate mean, median, and SD for each metric\n",
        "    energy_mean <- mean(data[[ENERGY]], na.rm = TRUE)\n",
        "    energy_median <- median(data[[ENERGY]], na.rm = TRUE)\n",
        "    energy_sd <- sd(data[[ENERGY]], na.rm = TRUE)\n",
        "\n",
        "    time_mean <- mean(data[[TIME]], na.rm = TRUE)\n",
        "    time_median <- median(data[[TIME]], na.rm = TRUE)\n",
        "    time_sd <- sd(data[[TIME]], na.rm = TRUE)\n",
        "\n",
        "    cpu_mean <- mean(data[[CPU]], na.rm = TRUE)\n",
        "    cpu_median <- median(data[[CPU]], na.rm = TRUE)\n",
        "    cpu_sd <- sd(data[[CPU]], na.rm = TRUE)\n",
        "\n",
        "    gpu_mean <- mean(data[[GPU]], na.rm = TRUE)\n",
        "    gpu_median <- median(data[[GPU]], na.rm = TRUE)\n",
        "    gpu_sd <- sd(data[[GPU]], na.rm = TRUE)\n",
        "\n",
        "    memory_mean <- mean(data[[MEMORY]], na.rm = TRUE)\n",
        "    memory_median <- median(data[[MEMORY]], na.rm = TRUE)\n",
        "    memory_sd <- sd(data[[MEMORY]], na.rm = TRUE)\n",
        "\n",
        "    # Print row in LaTeX format\n",
        "    if (method == ON_DEVICE) {\n",
        "      cat(sprintf(\"        \\\\textbf{%s (%d words)} & \\\\textbf{On-Device} & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f \\\\\\\\ \\n\",\n",
        "                  tools::toTitleCase(label), length_value,\n",
        "                  energy_mean, energy_median, energy_sd,\n",
        "                  time_mean, time_median, time_sd,\n",
        "                  cpu_mean, cpu_median, cpu_sd,\n",
        "                  gpu_mean, gpu_median, gpu_sd,\n",
        "                  memory_mean, memory_median, memory_sd))\n",
        "    } else {\n",
        "      cat(sprintf(\"        & \\\\textbf{Remote} & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f & %.2f \\\\\\\\ \\n\",\n",
        "                  energy_mean, energy_median, energy_sd,\n",
        "                  time_mean, time_median, time_sd,\n",
        "                  cpu_mean, cpu_median, cpu_sd,\n",
        "                  gpu_mean, gpu_median, gpu_sd,\n",
        "                  memory_mean, memory_median, memory_sd))\n",
        "    }\n",
        "\n",
        "    # Add \\hline after Remote entry except for the last label\n",
        "    if (method == REMOTE && label != tail(names(LENGTH_MAP), n = 1)) {\n",
        "      cat(\"        \\\\hline\\n\")\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "# Close LaTeX table\n",
        "cat(\"    \\\\hline\\n\")\n",
        "cat(\"    \\\\end{tabular}\\n\")\n",
        "cat(\"    }\\n\")\n",
        "cat(\"    \\\\label{table:performance_metrics}\\n\")\n",
        "cat(\"\\\\end{table*}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc-5tF8k08Ia",
        "outputId": "5c2e8a5f-5696-41fa-fd1f-b1e661574296"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{table*}[htbp]\n",
            "    \\centering\n",
            "    \\caption{Mean, Median, and Standard Deviation (SD) of Energy Usage and Performance Metrics for Fetching LLM Content On-Device vs. Remote Across Varying Content Lengths}\n",
            "    \\scalebox{0.8}{\n",
            "    \\begin{tabular}{|l|l|ccc|ccc|ccc|ccc|ccc|}\n",
            "        \\hline\n",
            "        \\multirow{2}{*}{\\textbf{Content Length}} & \\multirow{2}{*}{\\textbf{Treatment}} & \\multicolumn{3}{c|}{\\textbf{Energy Usage (Joule)}} & \\multicolumn{3}{c|}{\\textbf{Execution Time (second)}} & \\multicolumn{3}{c|}{\\textbf{Average CPU Usage (\\%)}} & \\multicolumn{3}{c|}{\\textbf{Average GPU Usage (\\%)}} & \\multicolumn{3}{c|}{\\textbf{Average Memory Usage (\\%)}} \\\\ \n",
            "        \\cline{3-17}\n",
            "        & & \\textbf{Mean} & \\textbf{Median} & \\textbf{SD} & \\textbf{Mean} & \\textbf{Median} & \\textbf{SD} & \\textbf{Mean} & \\textbf{Median} & \\textbf{SD} & \\textbf{Mean} & \\textbf{Median} & \\textbf{SD} & \\textbf{Mean} & \\textbf{Median} & \\textbf{SD} \\\\ \n",
            "        \\hline\n",
            "        \\textbf{Short (100 words)} & \\textbf{On-Device} & 52.82 & 55.00 & 20.94 & 15.07 & 15.47 & 3.44 & 4.93 & 4.43 & 1.84 & 77.95 & 77.81 & 11.65 & 70.13 & 71.25 & 7.21 \\\\ \n",
            "        & \\textbf{Remote} & 15.18 & 14.30 & 5.86 & 8.90 & 8.76 & 0.97 & 9.95 & 8.60 & 4.10 & 0.72 & 0.72 & 0.27 & 57.03 & 56.00 & 5.86 \\\\ \n",
            "        \\hline\n",
            "        \\textbf{Medium (500 words)} & \\textbf{On-Device} & 349.34 & 403.80 & 179.15 & 35.99 & 38.77 & 12.16 & 3.54 & 3.37 & 0.76 & 93.06 & 92.79 & 4.23 & 71.27 & 72.85 & 7.20 \\\\ \n",
            "        & \\textbf{Remote} & 41.01 & 47.55 & 14.18 & 13.17 & 14.21 & 2.35 & 5.12 & 4.53 & 2.14 & 0.29 & 0.23 & 0.15 & 56.81 & 56.48 & 5.04 \\\\ \n",
            "        \\hline\n",
            "        \\textbf{Long (1000 words)} & \\textbf{On-Device} & 431.97 & 462.50 & 246.92 & 43.35 & 43.19 & 18.50 & 3.52 & 3.36 & 0.68 & 93.23 & 93.72 & 4.25 & 71.26 & 72.65 & 7.31 \\\\ \n",
            "        & \\textbf{Remote} & 48.56 & 47.80 & 19.86 & 14.38 & 14.30 & 3.29 & 4.51 & 4.22 & 1.68 & 0.26 & 0.22 & 0.13 & 56.63 & 56.22 & 5.06 \\\\ \n",
            "    \\hline\n",
            "    \\end{tabular}\n",
            "    }\n",
            "    \\label{table:performance_metrics}\n",
            "\\end{table*}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwScFI9ye_BN"
      },
      "source": [
        "# Normality Check"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize data for manual normality check"
      ],
      "metadata": {
        "id": "0fMg72YC8gaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the density folder if it exists, including its contents\n",
        "system(\"rm -rf density_plots\")"
      ],
      "metadata": {
        "id": "u2555oT9f50B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through the plot folders and create them if they don't exist\n",
        "for (folder in PLOT_FOLDERS) {\n",
        "  if (!dir.exists(folder)) {\n",
        "    dir.create(folder)\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "NGkUM6IhgChV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Violin and Density Plots"
      ],
      "metadata": {
        "id": "Tn4vRKiR664X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "2h-nBKS9fBK2"
      },
      "outputs": [],
      "source": [
        "# Re-usable functions to make density plots and violin plots\n",
        "density_plot <- function(dataset, title, x, y, show_legend = TRUE) {\n",
        "  ggplot(dataset, aes(x = Values, fill = Distribution)) +\n",
        "    geom_density(alpha = 0.5) +\n",
        "    scale_fill_manual(values = COLOR_MAP) +  # Use COLOR_MAP for colors\n",
        "    labs(\n",
        "      title = title,\n",
        "      x = x,\n",
        "      y = y\n",
        "    ) +\n",
        "    theme_minimal() +\n",
        "    theme(\n",
        "      legend.position = ifelse(show_legend, \"right\", \"none\"),  # Control legend display\n",
        "      legend.title = element_blank(),\n",
        "      legend.text = element_text(size = rel(FONT_MULTIPLIER)),  # Increase legend text size\n",
        "      axis.title = element_text(size = rel(FONT_MULTIPLIER)),\n",
        "      axis.text = element_text(size = rel(FONT_MULTIPLIER)),\n",
        "      plot.title = element_text(size = rel(1.1 * FONT_MULTIPLIER))\n",
        "    )\n",
        "}\n",
        "\n",
        "violin_plot <- function(dataset, title, x, y, show_legend = TRUE) {\n",
        "  ggplot(dataset, aes(x = Distribution, y = Values, fill = Distribution)) +\n",
        "    geom_violin(alpha = 0.5) +\n",
        "    geom_boxplot(width = 0.045, outlier.shape = NA) +\n",
        "    scale_fill_manual(values = COLOR_MAP) +  # Use COLOR_MAP for colors\n",
        "    labs(\n",
        "      title = title,\n",
        "      x = x,\n",
        "      y = y\n",
        "    ) +\n",
        "    theme_minimal() +\n",
        "    theme(\n",
        "      legend.position = ifelse(show_legend, \"right\", \"none\"),  # Control legend display\n",
        "      legend.title = element_blank(),\n",
        "      legend.text = element_text(size = rel(FONT_MULTIPLIER)),  # Increase legend text size\n",
        "      axis.title = element_text(size = rel(FONT_MULTIPLIER)),\n",
        "      axis.text = element_text(size = rel(FONT_MULTIPLIER)),\n",
        "      plot.title = element_text(size = rel(1.1 * FONT_MULTIPLIER))\n",
        "    )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_plots_for_metric <- function(metric_name) {\n",
        "  # Set up directories for the specific metric if they don't exist\n",
        "  density_dir <- paste0(DENSITY_FOLDER, \"/\", metric_name)\n",
        "  violin_dir <- paste0(VIOLIN_FOLDER, \"/\", metric_name)\n",
        "\n",
        "  if (!dir.exists(density_dir)) {\n",
        "    dir.create(density_dir, recursive = TRUE)\n",
        "  }\n",
        "  if (!dir.exists(violin_dir)) {\n",
        "    dir.create(violin_dir, recursive = TRUE)\n",
        "  }\n",
        "\n",
        "  # List to store each plot for grid arrangement\n",
        "  density_plots <- list()\n",
        "  violin_plots <- list()\n",
        "\n",
        "  # Collect all values across content lengths for consistent axis limits\n",
        "  all_values <- unlist(lapply(names(LENGTH_MAP), function(label) {\n",
        "    c(\n",
        "      subset_data[[paste(ON_DEVICE, label, sep = \"_\")]][[metric_name]],\n",
        "      subset_data[[paste(REMOTE, label, sep = \"_\")]][[metric_name]]\n",
        "    )\n",
        "  }))\n",
        "\n",
        "  # Loop over content lengths to create individual density and violin plots\n",
        "  for (label in names(LENGTH_MAP)) {\n",
        "    length_value <- LENGTH_MAP[[label]]\n",
        "\n",
        "    # Create combined data for On-Device and Remote for this length\n",
        "    combined_data <- bind_rows(\n",
        "      subset_data[[paste(ON_DEVICE, label, sep = \"_\")]] %>%\n",
        "        mutate(Distribution = ON_DEVICE, Values = .[[metric_name]]),\n",
        "      subset_data[[paste(REMOTE, label, sep = \"_\")]] %>%\n",
        "        mutate(Distribution = REMOTE, Values = .[[metric_name]])\n",
        "    )\n",
        "\n",
        "    # Determine whether to show legend based on label (only for the last plot)\n",
        "    show_legend <- FALSE\n",
        "\n",
        "    # Create density plot\n",
        "    plot_title_density <- paste(tools::toTitleCase(label), \" (\", length_value, \")\", sep = \"\")\n",
        "    density_plot_obj <- density_plot(combined_data, plot_title_density, AXIS_LABELS[[metric_name]], \"Density\", show_legend)\n",
        "    density_plot_obj_for_combined <- density_plot(combined_data, plot_title_density, AXIS_LABELS[[metric_name]],\n",
        "                                                  ifelse(label == \"short\", \"Density\", \"\"), show_legend)\n",
        "\n",
        "    # Save individual density plot without x-axis limit for auto-adjusted scaling\n",
        "    ggsave(filename = paste0(density_dir, \"/density_plot_\", label, \".pdf\"),\n",
        "           plot = density_plot_obj,\n",
        "           width = WIDTH, height = HEIGHT)\n",
        "\n",
        "    # Add x-axis limits for consistent axis in the combined plot\n",
        "    density_plots[[label]] <- density_plot_obj_for_combined + xlim(range(all_values, na.rm = TRUE))\n",
        "\n",
        "    # Create violin plot\n",
        "    plot_title_violin <- paste(tools::toTitleCase(label), \" (\", length_value, \")\", sep = \"\")\n",
        "    violin_plot_obj <- violin_plot(combined_data, plot_title_violin, \"\", AXIS_LABELS[[metric_name]], show_legend)\n",
        "    violin_plot_obj_for_combined <- violin_plot(combined_data, plot_title_violin, \"\",\n",
        "                                                ifelse(label == \"short\", AXIS_LABELS[[metric_name]], \"\"), show_legend)\n",
        "\n",
        "    # Save individual violin plot\n",
        "    ggsave(filename = paste0(violin_dir, \"/violin_plot_\", label, \".pdf\"),\n",
        "           plot = violin_plot_obj,\n",
        "           width = WIDTH, height = HEIGHT)\n",
        "\n",
        "    # Add y-axis limits for consistent axis in the combined plot\n",
        "    violin_plots[[label]] <- violin_plot_obj_for_combined + ylim(range(all_values, na.rm = TRUE))\n",
        "  }\n",
        "\n",
        "  # Arrange all density plots in a 1-row grid with consistent x-axis limits\n",
        "  combined_density_plot <- plot_grid(density_plots$short, density_plots$medium, density_plots$long, nrow = 1)\n",
        "  ggsave(paste0(density_dir, \"/combined_density_plots_\", metric_name, \".pdf\"), combined_density_plot, width = WIDTH * length(LENGTH_MAP), height = HEIGHT)\n",
        "\n",
        "  # Arrange all violin plots in a 1-row grid with consistent y-axis limits\n",
        "  combined_violin_plot <- plot_grid(violin_plots$short, violin_plots$medium, violin_plots$long, nrow = 1)\n",
        "  ggsave(paste0(violin_dir, \"/combined_violin_plots_\", metric_name, \".pdf\"), combined_violin_plot, width = WIDTH * length(LENGTH_MAP), height = HEIGHT)\n",
        "}\n"
      ],
      "metadata": {
        "id": "ufrBtFOCc4iV"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each metric and generate plots\n",
        "for (metric_name in METRICS) {\n",
        "  generate_plots_for_metric(metric_name)\n",
        "}"
      ],
      "metadata": {
        "id": "jHDf2oGDd3Nx"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Special Violin Plot for Each LLMs\n",
        "- On-device\n",
        "- 7 LLMs\n",
        "- 3 content lengths\n",
        "--> to qualitatively judge their spreads"
      ],
      "metadata": {
        "id": "POzfNCKvs3sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_llm_data <- list()\n",
        "\n",
        "# Loop over each LLM\n",
        "for (llm_key in names(LLM_NAMES)) {\n",
        "  llm_name <- LLM_NAMES[[llm_key]]  # Get the full LLM name\n",
        "  for (method in c(ON_DEVICE, REMOTE)) {\n",
        "    for (label in names(LENGTH_MAP)) {\n",
        "      length_value <- LENGTH_MAP[[label]]\n",
        "      subset_name <- paste(method, label, sep = \"_\")  # e.g., \"on_device_short\"\n",
        "\n",
        "      # Access the relevant data subset for the method and length\n",
        "      if (subset_name %in% names(subset_data)) {\n",
        "        filtered_data <- subset_data[[subset_name]]\n",
        "\n",
        "        # Filter for the specific LLM based on the \"model\" column\n",
        "        llm_filtered_data <- filtered_data %>%\n",
        "          filter(model == tolower(gsub(\" \", \":\", llm_name)))  # Convert to match the model format in data\n",
        "\n",
        "        # Store the result in the filtered_llm_data list\n",
        "        filtered_llm_data[[paste(llm_name, label, method, sep = \"_\")]] <- llm_filtered_data\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "HlEAD6C_uDak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de388c0b-e063-401b-c8d1-4a5d96c129f6"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_violin_plots_each_llm <- function(filtered_llm_data, metric_name) {\n",
        "  # Set up directories for the specific metric if they don't exist\n",
        "  violin_dir <- paste0(VIOLIN_FOLDER, \"/\", metric_name)\n",
        "\n",
        "  if (!dir.exists(violin_dir)) {\n",
        "    dir.create(violin_dir, recursive = TRUE)\n",
        "  }\n",
        "\n",
        "  # List to store each plot for grid arrangement\n",
        "  violin_plots <- list()\n",
        "\n",
        "  # Collect all values across content lengths for consistent axis limits\n",
        "  all_values <- unlist(lapply(names(LENGTH_MAP), function(label) {\n",
        "    sapply(names(LLM_NAMES), function(llm_key) {\n",
        "      on_device_data <- subset_data[[paste(ON_DEVICE, label, sep = \"_\")]] %>%\n",
        "        filter(model == tolower(gsub(\" \", \":\", LLM_NAMES[[llm_key]]))) %>%\n",
        "        pull(!!sym(metric_name))\n",
        "      return(on_device_data)\n",
        "    })\n",
        "  }))\n",
        "\n",
        "  # Loop over content lengths to create individual density and violin plots\n",
        "  for (label in names(LENGTH_MAP)) {\n",
        "    length_value <- LENGTH_MAP[[label]]\n",
        "\n",
        "    # Initialize a list to collect all On-Device data for this length\n",
        "    combined_data_list <- list()\n",
        "\n",
        "    # Loop through each LLM and gather On-Device data\n",
        "    for (llm_key in names(LLM_NAMES)) {\n",
        "      llm_name <- LLM_NAMES[[llm_key]]\n",
        "\n",
        "      # Access On-Device data for the specific LLM\n",
        "      on_device_data <- subset_data[[paste(ON_DEVICE, label, sep = \"_\")]] %>%\n",
        "        filter(model == tolower(gsub(\" \", \":\", llm_name))) %>%\n",
        "        mutate(Distribution = ON_DEVICE, Values = .[[metric_name]], LLM = llm_key)\n",
        "\n",
        "      # Add the On-Device data to the list\n",
        "      if (nrow(on_device_data) > 0) {\n",
        "        combined_data_list[[llm_key]] <- on_device_data\n",
        "      }\n",
        "    }\n",
        "\n",
        "    # Combine all On-Device data into a single dataframe\n",
        "    combined_data <- bind_rows(combined_data_list)\n",
        "\n",
        "    # Set LLM order as specified in LLM_NAMES, ensuring factor levels match keys in LLM_COLOR_MAP\n",
        "    combined_data$LLM <- factor(combined_data$LLM, levels = names(LLM_NAMES))\n",
        "\n",
        "    # Create plot title for the current content length\n",
        "    plot_title_violin <- paste(tools::toTitleCase(label), \" (\", length_value, \")\", sep = \"\")\n",
        "\n",
        "    # Generate the violin plot\n",
        "    violin_plot_obj_for_combined <- ggplot(combined_data, aes(x = LLM, y = Values, fill = LLM)) +\n",
        "      geom_violin(position = \"dodge\", alpha = 0.5, trim = FALSE) +\n",
        "      geom_boxplot(width = 0.07, color = \"black\", alpha = 0.6, outlier.shape = NA) +\n",
        "      scale_fill_manual(values = LLM_COLOR_MAP) +  # Directly use LLM_COLOR_MAP without subsetting\n",
        "      labs(\n",
        "        title = plot_title_violin,\n",
        "        x = \"\",\n",
        "        y = ifelse(label == \"short\", AXIS_LABELS[[metric_name]], \"\")  # Display y-axis label only for the first plot\n",
        "      ) +\n",
        "      theme_minimal() +\n",
        "      theme(\n",
        "        legend.position = \"none\",  # Hide legend for individual plots\n",
        "        axis.title = element_text(size = rel(FONT_MULTIPLIER)),\n",
        "        axis.text = element_text(size = rel(FONT_MULTIPLIER)),\n",
        "        plot.title = element_text(size = rel(1.1 * FONT_MULTIPLIER)),\n",
        "        axis.text.x = element_blank()  # Hide x-axis text\n",
        "      )\n",
        "\n",
        "    # Add y-axis limits for consistent axis across all plots\n",
        "    violin_plots[[label]] <- violin_plot_obj_for_combined + ylim(range(all_values, na.rm = TRUE))\n",
        "  }\n",
        "\n",
        "  # Create a separate legend plot by using a dummy bar plot to generate the legend\n",
        "  legend_plot <- ggplot(combined_data, aes(x = LLM, fill = LLM)) +\n",
        "    geom_bar(stat = \"count\", width = 0, alpha = 0.5) +\n",
        "    scale_fill_manual(values = LLM_COLOR_MAP) +\n",
        "    theme_void() +\n",
        "    theme(\n",
        "      legend.position = \"bottom\",  # Place the legend at the bottom\n",
        "      legend.box = \"horizontal\",\n",
        "      legend.title = element_blank(),\n",
        "      legend.text = element_text(size = rel(FONT_MULTIPLIER)),\n",
        "    ) +\n",
        "    scale_fill_manual(\n",
        "      values = LLM_COLOR_MAP,\n",
        "      labels = function(x) paste0(x, \"   \")  # Add spaces after each legend label\n",
        "    ) +\n",
        "    guides(fill = guide_legend(ncol = 7))  # Ensure the legend wraps to a new row\n",
        "\n",
        "\n",
        "\n",
        "  # Arrange all violin plots in a 1-row grid with consistent y-axis limits\n",
        "  combined_violin_plot <- plot_grid(\n",
        "    violin_plots$short, violin_plots$medium, violin_plots$long,\n",
        "    nrow = 1,\n",
        "    labels = NULL,  # No labels for the plots\n",
        "    rel_widths = c(1, 1, 1)  # Equal width for each plot\n",
        "  )\n",
        "\n",
        "  # Add the legend plot below the combined violin plot\n",
        "  combined_violin_plot_with_legend <- plot_grid(\n",
        "    combined_violin_plot, legend_plot,\n",
        "    nrow = 2,\n",
        "    rel_heights = c(9, 1)  # Adjust the height to make room for the legend at the bottom\n",
        "  )\n",
        "\n",
        "  # Save the combined violin plot with legend at the bottom\n",
        "  ggsave(paste0(violin_dir, \"/combined_violin_plots_llms_\", metric_name, \".pdf\"),\n",
        "         combined_violin_plot_with_legend,\n",
        "         width = WIDTH * length(LENGTH_MAP), height = HEIGHT)\n",
        "}\n",
        "\n",
        "# Call the function to generate violin plots for energy usage\n",
        "generate_violin_plots_each_llm(filtered_llm_data, ENERGY)\n"
      ],
      "metadata": {
        "id": "7Zha6RSBskKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5f12bb-1f45-4e0e-fdbe-84739e4f8f12"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m\u001b[22mScale for \u001b[32mfill\u001b[39m is already present.\n",
            "Adding another scale for \u001b[32mfill\u001b[39m, which will replace the existing scale.\n",
            "Warning message:\n",
            "“\u001b[1m\u001b[22mRemoved 192 rows containing missing values or values outside the scale range\n",
            "(`geom_violin()`).”\n",
            "Warning message:\n",
            "“\u001b[1m\u001b[22mRemoved 145 rows containing missing values or values outside the scale range\n",
            "(`geom_violin()`).”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oM0rJinE9RW"
      },
      "source": [
        "### QQ Plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_qq_plots_for_metric <- function(metric_name) {\n",
        "  # Function to create QQ plot\n",
        "  create_qq_plot <- function(data, title) {\n",
        "    qqPlot(data, main = title, ylab = AXIS_LABELS[[metric_name]],\n",
        "           col = \"blue\", col.lines = \"red\", pch = 16, cex = 0.7)\n",
        "  }\n",
        "\n",
        "  # Loop over methods (on-device and remote)\n",
        "  for (method in c(ON_DEVICE, REMOTE)) {\n",
        "    # Set up directory for the specific metric and method\n",
        "    qq_dir <- file.path(QQ_FOLDER, tolower(method), metric_name)\n",
        "    dir.create(qq_dir, recursive = TRUE, showWarnings = FALSE)\n",
        "\n",
        "    # Loop over content lengths\n",
        "    for (label in names(LENGTH_MAP)) {\n",
        "      length_value <- LENGTH_MAP[[label]]\n",
        "      subset_name <- paste(method, label, sep = \"_\")\n",
        "\n",
        "      # Get the data for this subset\n",
        "      data <- subset_data[[subset_name]][[metric_name]]\n",
        "\n",
        "      # Create and save the QQ plot\n",
        "      plot_title <- paste(tools::toTitleCase(method), \" - \", tools::toTitleCase(label),\n",
        "                    \" (\", length_value, \")\", sep = \"\")\n",
        "      pdf(file.path(qq_dir, paste0(\"qq_plot_\", label, \".pdf\")),\n",
        "          width = WIDTH, height = HEIGHT)\n",
        "      create_qq_plot(data, plot_title)\n",
        "      dev.off()\n",
        "    }\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "sd1cH9Gf7Fvw"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each metric and generate qq plots\n",
        "for (metric_name in METRICS) {\n",
        "  generate_qq_plots_for_metric(metric_name)\n",
        "}"
      ],
      "metadata": {
        "id": "KavEUZ1_7KXO"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0fbB82WBv-X"
      },
      "source": [
        "## Normality Testing Using Shapiro-Wilks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh3BrBYbCrEs"
      },
      "source": [
        "### Shapiro-Wilks Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV-Uds9UCx4i"
      },
      "source": [
        "* A low p-value (typically less than 0.05) indicates that the data significantly deviates from a normal distribution, providing evidence to reject the null hypothesis. In other words, it suggests non-normality.\n",
        "* It is calculated during the Shapiro-Wilk test and is used to assess the degree of normality in the data. The value of W ranges between 0 and 1, where 1 indicates perfect normality.\n",
        "* The smaller the W statistic, the stronger the evidence against the null hypothesis (the assumption that the data follows a normal distribution). Smaller W values suggest departures from normality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mY_cWl6LBspV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeaf7d3f-adf6-49ab-a4ab-3311ac098eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        subset_name         W      p_value\n",
            "W   on_device_short 0.9547488 3.202963e-05\n",
            "W1 on_device_medium 0.8745747 3.521535e-11\n",
            "W2   on_device_long 0.9290627 5.084372e-08\n",
            "W3     remote_short 0.8594111 1.116692e-11\n",
            "W4    remote_medium 0.9094642 2.101168e-08\n",
            "W5      remote_long 0.9322779 6.199450e-07\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty data frame to store results\n",
        "shapiro_results_df <- data.frame(\n",
        "  subset_name = character(),\n",
        "  W = numeric(),\n",
        "  p_value = numeric(),\n",
        "  stringsAsFactors = FALSE\n",
        ")\n",
        "\n",
        "# Loop through each subset and perform the Shapiro-Wilk test\n",
        "for (subset_name in names(subset_data)) {\n",
        "  data_subset <- subset_data[[subset_name]]\n",
        "\n",
        "  # Perform the Shapiro-Wilk test\n",
        "  test_result <- shapiro.test(data_subset[[ENERGY]])\n",
        "\n",
        "  # Append results to the data frame\n",
        "  shapiro_results_df <- rbind(shapiro_results_df, data.frame(\n",
        "    subset_name = subset_name,\n",
        "    W = test_result$statistic,\n",
        "    p_value = test_result$p.value,\n",
        "    stringsAsFactors = FALSE\n",
        "  ))\n",
        "}\n",
        "\n",
        "# Print the results as a table\n",
        "print(shapiro_results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1os-nvKUF-2a"
      },
      "source": [
        "## Find skewed data, apply transformation (if applicable), and check if normality is enhanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8M_yiGPmF0LJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f7617f3-b8b2-4c5a-a9f6-b24401c00e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "short  on_device:  Negatively Skewed \n",
            "short  remote:  Positively Skewed \n",
            "[1] \"on_device and remote datasets are not skewed similarly, so no transformation is applied.\"\n",
            "medium  on_device:  Negatively Skewed \n",
            "medium  remote:  Negatively Skewed \n",
            "long  on_device:  Negatively Skewed \n",
            "long  remote:  Negatively Skewed \n",
            "   Transformation Shapiro_on_device_p_value Shapiro_Remote_p_value\n",
            "1        Original              3.521535e-11           2.101168e-08\n",
            "2         Power 2              7.749464e-10           4.230615e-09\n",
            "3         Power 3              1.663134e-15           4.418860e-14\n",
            "4        Original              3.521535e-11           2.101168e-08\n",
            "5         Power 2              7.749464e-10           4.230615e-09\n",
            "6         Power 3              1.663134e-15           4.418860e-14\n",
            "7        Original              5.084372e-08           6.199450e-07\n",
            "8         Power 2              3.038347e-09           8.610354e-08\n",
            "9         Power 3              1.149680e-14           9.411754e-11\n",
            "10       Original              5.084372e-08           6.199450e-07\n",
            "11        Power 2              3.038347e-09           8.610354e-08\n",
            "12        Power 3              1.149680e-14           9.411754e-11\n"
          ]
        }
      ],
      "source": [
        "# Function to check skewness\n",
        "check_skew <- function(skew) {\n",
        "  if (skew > 0) {\n",
        "    return(\"Positively Skewed\")\n",
        "  } else if (skew < 0) {\n",
        "    return(\"Negatively Skewed\")\n",
        "  } else {\n",
        "    return(\"Symmetric\")\n",
        "  }\n",
        "}\n",
        "\n",
        "# Function to transform data towards normality and check normality\n",
        "transform_pairs_towards_normality <- function(on_device, remote, name) {\n",
        "  # Calculate skewness of datasets\n",
        "  on_device_skew <- skewness(on_device)\n",
        "  remote_skew <- skewness(remote)\n",
        "\n",
        "  results_skew_on_device <- check_skew(on_device_skew)\n",
        "  results_skew_remote <- check_skew(remote_skew)\n",
        "\n",
        "  # Print skewness results\n",
        "  cat(name, \" on_device: \", results_skew_on_device, \"\\n\")\n",
        "  cat(name, \" remote: \", results_skew_remote, \"\\n\")\n",
        "\n",
        "  # Prepare a data frame to store results\n",
        "  results_df <- data.frame(\n",
        "    Transformation = character(),\n",
        "    Shapiro_on_device_p_value = numeric(),\n",
        "    Shapiro_Remote_p_value = numeric(),\n",
        "    stringsAsFactors = FALSE\n",
        "  )\n",
        "\n",
        "  # Check skewness and apply transformations\n",
        "  if (results_skew_on_device == results_skew_remote) {\n",
        "    if (results_skew_on_device == \"Positively Skewed\") {\n",
        "      # Transformations for positive skew\n",
        "      on_device_sqrt <- sqrt(on_device)\n",
        "      remote_sqrt <- sqrt(remote)\n",
        "      on_device_log <- log(on_device)\n",
        "      remote_log <- log(remote)\n",
        "\n",
        "      # Test normality differences\n",
        "      shapiro_on_device <- shapiro.test(on_device)\n",
        "      shapiro_remote <- shapiro.test(remote)\n",
        "      shapiro_on_device_sqrt <- shapiro.test(on_device_sqrt)\n",
        "      shapiro_remote_sqrt <- shapiro.test(remote_sqrt)\n",
        "      shapiro_on_device_log <- shapiro.test(on_device_log)\n",
        "      shapiro_remote_log <- shapiro.test(remote_log)\n",
        "\n",
        "      # Store results in data frame\n",
        "      results_df <- rbind(results_df, data.frame(\n",
        "        Transformation = \"Original\",\n",
        "        Shapiro_on_device_p_value = shapiro_on_device$p.value,\n",
        "        Shapiro_Remote_p_value = shapiro_remote$p.value\n",
        "      ))\n",
        "      results_df <- rbind(results_df, data.frame(\n",
        "        Transformation = \"Square Root\",\n",
        "        Shapiro_on_device_p_value = shapiro_on_device_sqrt$p.value,\n",
        "        Shapiro_Remote_p_value = shapiro_remote_sqrt$p.value\n",
        "      ))\n",
        "      results_df <- rbind(results_df, data.frame(\n",
        "        Transformation = \"Logarithm\",\n",
        "        Shapiro_on_device_p_value = shapiro_on_device_log$p.value,\n",
        "        Shapiro_Remote_p_value = shapiro_remote_log$p.value\n",
        "      ))\n",
        "\n",
        "    } else {\n",
        "      # Transformations for negative skew\n",
        "      on_device_power2 <- on_device^2\n",
        "      remote_power2 <- remote^2\n",
        "      on_device_power3 <- on_device^3\n",
        "      remote_power3 <- remote^3\n",
        "\n",
        "      # Test normality differences\n",
        "      shapiro_on_device <- shapiro.test(on_device)\n",
        "      shapiro_remote <- shapiro.test(remote)\n",
        "      shapiro_on_device_power2 <- shapiro.test(on_device_power2)\n",
        "      shapiro_remote_power2 <- shapiro.test(remote_power2)\n",
        "      shapiro_on_device_power3 <- shapiro.test(on_device_power3)\n",
        "      shapiro_remote_power3 <- shapiro.test(remote_power3)\n",
        "\n",
        "      # Store results in data frame\n",
        "      results_df <- rbind(results_df, data.frame(\n",
        "        Transformation = \"Original\",\n",
        "        Shapiro_on_device_p_value = shapiro_on_device$p.value,\n",
        "        Shapiro_Remote_p_value = shapiro_remote$p.value\n",
        "      ))\n",
        "      results_df <- rbind(results_df, data.frame(\n",
        "        Transformation = \"Power 2\",\n",
        "        Shapiro_on_device_p_value = shapiro_on_device_power2$p.value,\n",
        "        Shapiro_Remote_p_value = shapiro_remote_power2$p.value\n",
        "      ))\n",
        "      results_df <- rbind(results_df, data.frame(\n",
        "        Transformation = \"Power 3\",\n",
        "        Shapiro_on_device_p_value = shapiro_on_device_power3$p.value,\n",
        "        Shapiro_Remote_p_value = shapiro_remote_power3$p.value\n",
        "      ))\n",
        "    }\n",
        "  } else {\n",
        "    print(\"on_device and remote datasets are not skewed similarly, so no transformation is applied.\")\n",
        "  }\n",
        "\n",
        "  return(results_df)\n",
        "}\n",
        "\n",
        "# Collect results for each dataset\n",
        "final_results <- data.frame()\n",
        "\n",
        "for (length_label in names(LENGTH_MAP)) {  # Iterate over length labels\n",
        "  for (method in c(ON_DEVICE, REMOTE)) {\n",
        "    subset_name <- paste(method, length_label, sep = \"_\")  # Construct subset name\n",
        "    if (subset_name %in% names(subset_data)) {\n",
        "      data_subset <- subset_data[[subset_name]]\n",
        "      if (method == ON_DEVICE) {\n",
        "        results <- transform_pairs_towards_normality(data_subset[[ENERGY]],\n",
        "                                                      subset_data[[paste(REMOTE, length_label, sep = \"_\")]][[ENERGY]],\n",
        "                                                      length_label)\n",
        "      }\n",
        "      final_results <- rbind(final_results, results)\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "# Print the final results table\n",
        "print(final_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hWrZYdMh-mC"
      },
      "source": [
        "## H1. Hypothesis Testing and Effect Size Estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tfFauMyziN0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cbbb281-d253-4d5e-daf5-ecd07a277ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{table}[H]\n",
            "  \\centering\n",
            "  \\caption{Results for Hypothesis 1 - Energy Usage Difference Between On-device and Remote LLMs Content Fetching}\n",
            "  \\resizebox{\\columnwidth}{!}{%\n",
            "    \\begin{tabular}{lcccccc}\n",
            "      \\hline\n",
            "      \\textbf{Content Length} & \\textbf{W-Value} & \\textbf{P-Value} & \\textbf{Cliff’s Delta} & \\textbf{Lower CI} & \\textbf{Upper CI} & \\textbf{Delta} \\\\\n",
            "      \\hline\n",
            "      \\textbf{Short (100 words)} & 28370 & < 2.2e-16 & 0.941 & 0.905 & 0.964 & Large \\\\\n",
            "      \\hline\n",
            "      \\textbf{Medium (500 words)} & 28486 & < 2.2e-16 & 0.956 & 0.920 & 0.976 & Large \\\\\n",
            "      \\hline\n",
            "      \\textbf{Long (1000 words)} & 29587 & < 2.2e-16 & 0.912 & 0.868 & 0.942 & Large \\\\\n",
            "      \\hline\n",
            "    \\end{tabular}%\n",
            "}\n",
            "  \\label{table:h1}\n",
            "\\end{table}\n"
          ]
        }
      ],
      "source": [
        "# Initialize a data frame to store results\n",
        "results <- data.frame(\n",
        "  Content_Length = character(),\n",
        "  W_Value = numeric(),\n",
        "  P_Value = numeric(),\n",
        "  Cliffs_Delta = numeric(),\n",
        "  Lower_CI = numeric(),\n",
        "  Upper_CI = numeric(),\n",
        "  Delta = character(),\n",
        "  stringsAsFactors = FALSE\n",
        ")\n",
        "\n",
        "# Loop over content lengths and calculate the statistics using subset_data\n",
        "for (label in names(LENGTH_MAP)) {\n",
        "  length_value <- LENGTH_MAP[[label]]\n",
        "\n",
        "  # Get filtered data from subset_data\n",
        "  on_device_data <- subset_data[[paste(ON_DEVICE, label, sep = \"_\")]][[ENERGY]]\n",
        "  remote_data <- subset_data[[paste(REMOTE, label, sep = \"_\")]][[ENERGY]]\n",
        "\n",
        "  # Perform the Wilcoxon test\n",
        "  wilcoxon_result <- wilcox.test(on_device_data, remote_data, alternative = \"two.sided\")\n",
        "\n",
        "  # Perform the Cliff's delta test\n",
        "  cliff_result <- cliff.delta(on_device_data, remote_data, return.ci = TRUE)\n",
        "\n",
        "  # Append results to the data frame\n",
        "  results <- results %>% add_row(\n",
        "    Content_Length = sprintf(\"%s (%d words)\", tools::toTitleCase(label), length_value),\n",
        "    W_Value = wilcoxon_result$statistic,\n",
        "    P_Value = wilcoxon_result$p.value,\n",
        "    Cliffs_Delta = cliff_result$estimate,\n",
        "    Lower_CI = cliff_result$conf.int[1],\n",
        "    Upper_CI = cliff_result$conf.int[2],\n",
        "    Delta = case_when(\n",
        "      abs(cliff_result$estimate) < 0.147 ~ \"Negligible\",\n",
        "      abs(cliff_result$estimate) < 0.33 ~ \"Small\",\n",
        "      abs(cliff_result$estimate) < 0.474 ~ \"Medium\",\n",
        "      TRUE ~ \"Large\"\n",
        "    )\n",
        "  )\n",
        "}\n",
        "\n",
        "# Prepare LaTeX table\n",
        "cat(\"\\\\begin{table}[H]\\n\")\n",
        "cat(\"  \\\\centering\\n\")\n",
        "cat(\"  \\\\caption{Results for Hypothesis 1 - Energy Usage Difference Between On-device and Remote LLMs Content Fetching}\\n\")\n",
        "cat(\"  \\\\resizebox{\\\\columnwidth}{!}{%\\n\")\n",
        "cat(\"    \\\\begin{tabular}{lcccccc}\\n\")\n",
        "cat(\"      \\\\hline\\n\")\n",
        "cat(\"      \\\\textbf{Content Length} & \\\\textbf{W-Value} & \\\\textbf{P-Value} & \\\\textbf{Cliff’s Delta} & \\\\textbf{Lower CI} & \\\\textbf{Upper CI} & \\\\textbf{Delta} \\\\\\\\\\n\")\n",
        "cat(\"      \\\\hline\\n\")\n",
        "\n",
        "# Loop through results to create table rows\n",
        "for (i in 1:nrow(results)) {\n",
        "  cat(sprintf(\"      \\\\textbf{%s} & %.0f & %s & %.3f & %.3f & %.3f & %s \\\\\\\\\\n\",\n",
        "              results$Content_Length[i],\n",
        "              ifelse(is.na(results$W_Value[i]), NA, results$W_Value[i]),\n",
        "              ifelse(is.na(results$P_Value[i]), \"NA\", ifelse(results$P_Value[i] < 0.001, \"< 2.2e-16\", sprintf(\"%.1e\", results$P_Value[i]))),\n",
        "              ifelse(is.na(results$Cliffs_Delta[i]), NA, results$Cliffs_Delta[i]),\n",
        "              ifelse(is.na(results$Lower_CI[i]), NA, results$Lower_CI[i]),\n",
        "              ifelse(is.na(results$Upper_CI[i]), NA, results$Upper_CI[i]),\n",
        "              ifelse(is.na(results$Delta[i]), NA, results$Delta[i]))\n",
        "  )\n",
        "  cat(\"      \\\\hline\\n\")\n",
        "}\n",
        "\n",
        "cat(\"    \\\\end{tabular}%\n",
        "}\\n\")\n",
        "cat(\"  \\\\label{table:h1}\\n\")\n",
        "cat(\"\\\\end{table}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H2. Scatter Plots"
      ],
      "metadata": {
        "id": "x4Jm0D3TWED2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_scatter_plot_with_correlation <- function(dataset, x_var, y_var, title, x_title, y_title, color) {\n",
        "  ggplot(dataset, aes(x = !!sym(x_var), y = !!sym(y_var))) +\n",
        "    geom_point(color = \"black\", size=0.5) +  # Set points color to black\n",
        "  geom_smooth(method = \"lm\", se = FALSE, color = color) +  # Add correlation line with increased thickness\n",
        "    theme_minimal() +\n",
        "    theme(\n",
        "      plot.title = element_text(size = 4 * FONT_MULTIPLIER),\n",
        "      axis.title.x = element_text(size = 4 * FONT_MULTIPLIER),\n",
        "      axis.title.y = element_text(size = 4 * FONT_MULTIPLIER),\n",
        "      axis.text.x = element_text(size = 4 * FONT_MULTIPLIER),\n",
        "      axis.text.y = element_text(size = 4 * FONT_MULTIPLIER)\n",
        "    ) +\n",
        "    labs(\n",
        "      title = title,\n",
        "      x = x_title,\n",
        "      y = y_title\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "OtS0RyRhXavd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through all metrics to create combined plots\n",
        "for (metric in METRICS[-1]) {  # Exclude ENERGY from METRICS\n",
        "  # List to store plots for each length and method\n",
        "  plot_list <- list()\n",
        "\n",
        "  # Create a directory for the scatter plots if it does not exist\n",
        "  scatter_dir <- SCATTER_FOLDER\n",
        "  if (!dir.exists(scatter_dir)) {\n",
        "    dir.create(scatter_dir, recursive = TRUE)\n",
        "  }\n",
        "\n",
        "  # Iterate over each length label and method\n",
        "  for (method in c(ON_DEVICE, REMOTE)) {\n",
        "    for (label in names(LENGTH_MAP)) {\n",
        "      length_value <- LENGTH_MAP[[label]]\n",
        "      subset_name <- paste(method, label, sep = \"_\")  # Construct subset name\n",
        "\n",
        "      if (subset_name %in% names(subset_data)) {\n",
        "        data_subset <- subset_data[[subset_name]]\n",
        "\n",
        "        # Create scatter plot\n",
        "        plot_title <- paste(tools::toTitleCase(method), \" - \", tools::toTitleCase(label), \" (\", length_value, \")\", sep = \"\")\n",
        "        x_title <- AXIS_LABELS[[ENERGY]]\n",
        "        y_title <- AXIS_LABELS[[metric]]\n",
        "        color <- COLOR_MAP[[method]]  # Set color based on method\n",
        "\n",
        "        scatter_plot <- make_scatter_plot_with_correlation(\n",
        "          data_subset, ENERGY, metric, plot_title, ifelse(method == REMOTE, x_title, \"\"),\n",
        "          ifelse(label == \"short\", y_title, \"\"), color\n",
        "        ) # only include the x_title and y_title for left-most and bottom subplot\n",
        "\n",
        "        plot_list[[paste(method, label, sep = \"_\")]] <- scatter_plot  # Store plot in list\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  # Combine plots into a grid for both on-device and remote\n",
        "  combined_scatter_plot <- plot_grid(\n",
        "    plot_list[[paste(ON_DEVICE, \"short\", sep = \"_\")]],\n",
        "    plot_list[[paste(ON_DEVICE, \"medium\", sep = \"_\")]],\n",
        "    plot_list[[paste(ON_DEVICE, \"long\", sep = \"_\")]],\n",
        "    plot_list[[paste(REMOTE, \"short\", sep = \"_\")]],\n",
        "    plot_list[[paste(REMOTE, \"medium\", sep = \"_\")]],\n",
        "    plot_list[[paste(REMOTE, \"long\", sep = \"_\")]],\n",
        "    nrow = 2,\n",
        "    labels = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"),\n",
        "    align = 'hv'\n",
        "  )\n",
        "\n",
        "  # Save the combined plot to a PDF file\n",
        "  ggsave(filename = paste0(scatter_dir, \"/\", metric, \"_vs_\", ENERGY, \".pdf\"),\n",
        "         plot = combined_scatter_plot, width = WIDTH, height = WIDTH * 2 / 3)\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsRFkIIjWJe0",
        "outputId": "69160887-2d17-447e-bc43-e2f5eddb261e"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n",
            "\u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H2. Spearman"
      ],
      "metadata": {
        "id": "27Jh_zxxgM35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate and format Spearman correlations as LaTeX code\n",
        "calculate_spearman_latex <- function(subset_data) {\n",
        "\n",
        "  # Initialize an empty string to store LaTeX table rows\n",
        "  latex_rows <- \"\"\n",
        "\n",
        "  # Loop over methods (ON_DEVICE and REMOTE)\n",
        "  for (method in c(ON_DEVICE, REMOTE)) {\n",
        "    method_rows <- \"\"\n",
        "\n",
        "    # Loop over content length categories (short, medium, long)\n",
        "    for (label in names(LENGTH_MAP)) {\n",
        "      subset_name <- paste(method, label, sep = \"_\")\n",
        "\n",
        "      if (subset_name %in% names(subset_data)) {\n",
        "        data_subset <- subset_data[[subset_name]]\n",
        "\n",
        "        # Start row with content length label\n",
        "        row_label <- paste0(\"& \\\\textbf{\", tools::toTitleCase(label), \" (\", LENGTH_MAP[[label]], \")} & \")\n",
        "\n",
        "        # Container for correlation results\n",
        "        metric_results <- c()\n",
        "\n",
        "        # Iterate through each metric to correlate with energy usage\n",
        "        for (metric in c(TIME, CPU, GPU, MEMORY)) {\n",
        "          # Calculate Spearman correlation and p-value\n",
        "          spearman_test <- cor.test(data_subset[[ENERGY]], data_subset[[metric]], method = \"spearman\")\n",
        "          spearman_coef <- spearman_test$estimate\n",
        "          p_value <- spearman_test$p.value\n",
        "\n",
        "          # Format significance stars based on p-value\n",
        "          significance <- ifelse(p_value < 0.001, \"***\",\n",
        "                                 ifelse(p_value < 0.01, \"**\",\n",
        "                                        ifelse(p_value < 0.05, \"*\", \"\")))\n",
        "\n",
        "          # Format coefficient and p-value\n",
        "          formatted_coef <- formatC(spearman_coef, digits = 3, format = \"f\")\n",
        "          formatted_p_value <- formatC(p_value, digits = 3, format = \"f\")\n",
        "\n",
        "          # Append formatted result for the metric\n",
        "          formatted_p_value <- if (p_value < 0.001) {\n",
        "            \"<0.001\"\n",
        "          } else {\n",
        "            formatC(p_value, digits = 3, format = \"f\")\n",
        "          }\n",
        "\n",
        "          # Append formatted result for the metric\n",
        "          formatted_result <- if (p_value < 0.05) {\n",
        "            paste0(\"\\\\textbf{\", formatted_coef, \" (\", formatted_p_value, significance, \")}\")\n",
        "          } else {\n",
        "            paste0(formatted_coef, \" (\", formatted_p_value, significance, \")\")\n",
        "          }\n",
        "\n",
        "          metric_results <- c(metric_results, formatted_result)\n",
        "\n",
        "\n",
        "        }\n",
        "\n",
        "        # Concatenate row with all metrics\n",
        "        latex_row <- paste(row_label, paste(metric_results, collapse = \" & \"), \"\\\\\\\\ \\\\cline{2-6}\\n\")\n",
        "        method_rows <- paste(method_rows, latex_row, sep = \"\")\n",
        "      }\n",
        "    }\n",
        "\n",
        "    # Add multirow for method (ON_DEVICE or REMOTE)\n",
        "    multirow_start <- paste0(\"\\\\multirow{3}{*}{\\\\textbf{\", tools::toTitleCase(gsub(\"_\", \"-\", method)), \"}} \")\n",
        "    method_rows <- paste(multirow_start, method_rows)\n",
        "    latex_rows <- paste(latex_rows, method_rows, \"\\\\hline\\n\", sep = \"\")\n",
        "  }\n",
        "\n",
        "  # LaTeX table header and footer\n",
        "  latex_table <- paste0(\"\\\\begin{table*}[htbp]\\n\",\n",
        "                        \"    \\\\centering\\n\",\n",
        "                        \"    \\\\caption{Spearman Rank Correlation for Hypothesis 2: Energy Usage vs. Performance Metrics. \\n\",\n",
        "                        \"        Significance levels:\\\\\\\\\\n\",\n",
        "                        \"        * < 0.05, ** < 0.01, *** < 0.001 (\\\\textbf{bold} for significant p-values).\\n\",\n",
        "                        \"    }\\n\",\n",
        "                        \"    \\\\scalebox{0.8}{\\n\",\n",
        "                        \"    \\\\begin{tabular}{|l|l|c|c|c|c|}\\n\",\n",
        "                        \"        \\\\hline\\n\",\n",
        "                        \"        \\\\multirow{1}{*}{\\\\textbf{Treatment}} & \\\\multirow{1}{*}{\\\\textbf{Content length}} & \\\\multicolumn{1}{c|}{\\\\textbf{Energy usage vs Execution time}} & \\\\multicolumn{1}{c|}{\\\\textbf{Energy usage vs CPU usage}} & \\\\multicolumn{1}{c|}{\\\\textbf{Energy usage vs GPU usage}} & \\\\multicolumn{1}{c|}{\\\\textbf{Energy usage vs Memory usage}} \\\\\\\\\\n\",\n",
        "                        \"        \\\\hline\\n\",\n",
        "                        latex_rows,\n",
        "                        \"    \\\\end{tabular}\\n\",\n",
        "                        \"    }\\n\",\n",
        "                        \"    \\\\label{tab:spearman}\\n\",\n",
        "                        \"\\\\end{table*}\")\n",
        "\n",
        "  # Print or return the final LaTeX code\n",
        "  cat(latex_table)\n",
        "}\n",
        "\n",
        "# Call the function to print the LaTeX table\n",
        "calculate_spearman_latex(subset_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr1faakddyDH",
        "outputId": "5ede0f92-aec9-444c-917b-3591b202d258"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n",
            "Warning message in cor.test.default(data_subset[[ENERGY]], data_subset[[metric]], :\n",
            "“Cannot compute exact p-value with ties”\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{table*}[htbp]\n",
            "    \\centering\n",
            "    \\caption{Spearman Rank Correlation for Hypothesis 2: Energy Usage vs. Performance Metrics. \n",
            "        Significance levels:\\\\\n",
            "        * < 0.05, ** < 0.01, *** < 0.001 (\\textbf{bold} for significant p-values).\n",
            "    }\n",
            "    \\scalebox{0.8}{\n",
            "    \\begin{tabular}{|l|l|c|c|c|c|}\n",
            "        \\hline\n",
            "        \\multirow{1}{*}{\\textbf{Treatment}} & \\multirow{1}{*}{\\textbf{Content length}} & \\multicolumn{1}{c|}{\\textbf{Energy usage vs Execution time}} & \\multicolumn{1}{c|}{\\textbf{Energy usage vs CPU usage}} & \\multicolumn{1}{c|}{\\textbf{Energy usage vs GPU usage}} & \\multicolumn{1}{c|}{\\textbf{Energy usage vs Memory usage}} \\\\\n",
            "        \\hline\n",
            "\\multirow{3}{*}{\\textbf{On-Device}}  & \\textbf{Short (100)} &  \\textbf{0.991 (<0.001***)} & \\textbf{-0.708 (<0.001***)} & \\textbf{-0.176 (0.023*)} & \\textbf{0.541 (<0.001***)} \\\\ \\cline{2-6}\n",
            "& \\textbf{Medium (500)} &  \\textbf{0.928 (<0.001***)} & \\textbf{-0.284 (<0.001***)} & \\textbf{0.153 (0.039*)} & \\textbf{0.520 (<0.001***)} \\\\ \\cline{2-6}\n",
            "& \\textbf{Long (1000)} &  \\textbf{0.986 (<0.001***)} & \\textbf{-0.276 (<0.001***)} & \\textbf{0.315 (<0.001***)} & \\textbf{0.536 (<0.001***)} \\\\ \\cline{2-6}\n",
            "\\hline\n",
            "\\multirow{3}{*}{\\textbf{Remote}}  & \\textbf{Short (100)} &  \\textbf{0.891 (<0.001***)} & \\textbf{-0.785 (<0.001***)} & \\textbf{-0.647 (<0.001***)} & 0.010 (0.893) \\\\ \\cline{2-6}\n",
            "& \\textbf{Medium (500)} &  \\textbf{0.963 (<0.001***)} & \\textbf{-0.645 (<0.001***)} & \\textbf{-0.723 (<0.001***)} & -0.032 (0.692) \\\\ \\cline{2-6}\n",
            "& \\textbf{Long (1000)} &  \\textbf{0.983 (<0.001***)} & \\textbf{-0.710 (<0.001***)} & \\textbf{-0.640 (<0.001***)} & -0.045 (0.570) \\\\ \\cline{2-6}\n",
            "\\hline\n",
            "    \\end{tabular}\n",
            "    }\n",
            "    \\label{tab:spearman}\n",
            "\\end{table*}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Only on Google Colab] Download the Visualization Folders"
      ],
      "metadata": {
        "id": "Xy75aaV08wM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip(\"all_folders.zip\", files = unlist(lapply(PLOT_FOLDERS, function(folder) {\n",
        "  list.files(folder, full.names = TRUE, recursive = TRUE)\n",
        "})))\n",
        "\n"
      ],
      "metadata": {
        "id": "IEvPmEZW80kd"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then, manually download the exported .zip"
      ],
      "metadata": {
        "id": "ynoG_Kck9MnB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}